# Databricks Connection Template
# Copy this file to .env and update with your settings

# Database type
DB_TYPE=databricks

# Java configuration (required for JDBC)
# Examples:
#   macOS Homebrew: /opt/homebrew/opt/openjdk@17
#   Linux: /usr/lib/jvm/java-17-openjdk
#   Windows: C:/Program Files/Java/jdk-17
JAVA_HOME=/path/to/java/home

# Databricks workspace connection
DB_SERVER=your-workspace.cloud.databricks.com
DB_DATABASE=default
DB_PORT=443

# Authentication (using personal access token)
DB_USER=token
DB_PASSWORD=your-databricks-token-here

# Additional Databricks settings
# Update the warehouse ID in the httpPath (case-sensitive: lowercase 'h')
DB_EXTRA_SETTINGS=httpPath=/sql/1.0/warehouses/your-warehouse-id

# Schema configuration (Databricks uses catalog.schema format)
CDM_SCHEMA=omop.data
VOCABULARY_SCHEMA=omop.vocabulary
RESULTS_SCHEMA=your_project.results

# JDBC driver location
# Download from: https://www.databricks.com/spark/jdbc-drivers-download
JDBC_DRIVER_PATH=jdbc_drivers

# Performance settings
# Arrow optimization can significantly improve performance but requires:
# 1. Databricks JDBC driver with all Arrow dependencies
# 2. JVM options: -Dio.netty.tryReflectionSetAccessible=true
# 3. Sufficient memory allocation
# Set to TRUE only if your environment is properly configured
ENABLE_ARROW=FALSE

# DatabaseConnector optimization for bulk operations
# Enables bulk loading for 10-20x faster performance
DATABASE_CONNECTOR_BULK_UPLOAD=TRUE
# Batch size for insertTable operations (default: 1000)
DATABASE_CONNECTOR_BATCH_SIZE=10000

# Output configuration
OUTPUT_FOLDER=output